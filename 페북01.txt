머신러닝에서 중요한 것은 좋은 가설함수를 예측하는 것이고, 이 과정에서 발생하는 에러를 줄이는 것이 좋은 가설함수를 찾는 과정입니다. 내가 만든 모델이 잘 반응하고 있는지 좋은 결과를 얻으려면 어떤 과정을 거쳐야 할지 좋은 결과를 위해 어떤 보정을 거쳐야 하는지에 대해 이해를 위한 설명을 진행해 보겠습니다.
우리는 들어온 데이터를 사용해서 우리가 세운 함수에 대해 트레이닝 하고 또 테스팅을 합니다.
- 트레이닝 : 파라미터를 인퍼런스하는데 쓴다 
- 테스트: 새로운 데이터를 넣어서 트레이닝한 모델이 제대로 됐는지 확인해 보는 과정에 쓴다

이 과정에서 들어온 데이터에 대해 트레이닝을 하다보면 세 가지로 트레이닝된 데이터를 설명할 수 있습니다.
- underfitting : 트레이닝이 덜되서 한쪽으로 편향된 경우
- right fitting : 적당하게 피팅이 잘된 경우( 굉장히 잘 맞추지도 못맞추지도 않는 상황)
- overftting : 데이터 하나하나를 잘 맞추도록 피팅을 잘한 경우( 특정데이터에 너무나도 잘맞게 학습이 되어서 새로운 데이터가 들어왔을 때 더 큰에러를 생성할 수 있다)
과연 무엇이 가장 좋은 모델일까요? 이것을 판단하기 위해서는 기준이 필요하고 이론적으로 이해해야 기본을 탄탄하게 할 수 있습니다.
머신러닝 모델에서 좋고 나쁨을 판단하는 기준중 하나는 에러의 크기 인데요. 지금부터는 가장 중요한 에러에 대해 이야기해보려 합니다.

에러는 두 가지로 볼 수 있는데요. approximation 하는데서 생기는 에러인 bias와 generalization하는데서 생기는 에러 variance가 있습니다. 이 둘을 합친 것보다 작게 토탈에러가 발생하는 것이지요.  간단히 수식으로 설명을 드리자면 다음과 같습니다.                                                                                       
- g(d): 주어진 모든 데이터에 대해 파라미터 인퍼런스까지 다 된 함수
- g*: 현실에 있는 모든 데이터를 샘플링할 때마다 거기에 맞는 g(d)를 만들 수 있는데 이 무한개 g(d)의 값을 평균 낸 값
- f(x) : 학습하기 위한 타겟이자 트루 함수
- g(x) : 우리가 만들려는 모델
- (g(d) - g*)의 제곱 : 가설함수에 대한 에러 예측 함수

*variance = (g(d) - g*)제곱 
generalization에 대한 에러가 variance이고, 이를 낮추기 위해 데이터를 많이 모으는 방법이 있습니다
복잡한 모델의 경우 variance가 높고 bias가 낮습니다
*bias제곱 = (g* - f(x))제곱
모델의 특성때문에 생기는 에러, 한계점에 대한 에러입니다.(예: 우리 모델은 선형이야 라고 정해준 한계점으로 인한 에러, 리얼월드에 대한 데이터를 소화하기 어려워 생기는 에러)
approximation에 대한 에러가 bias이고 이를 낮추기 위해서는 모델을 복잡하게 만들면 됩니다. 그러나 variance가 안좋아지는 경우가 발생하고 오버피팅의 위험이 있습니다.
심플한 모델은 bias가 높고 variance가 낮기 때문입니다.

둘 사이에 trade off관계가 있기 때문에 에러를 해결하기 위해서는 이 관계를 분석하고 또 다른 태스크를 수행해야 합니다.
현실에서는 true function을 모르기 때문에 bias, variance를 계산할 수 있는 방법이 없습니다. infinite sampling이 중요한데 현실에서 안되기 때문에 사용하는 방법이 cross-validation입니다.
무한대의 데이터가 있다고 가정하기 위해서 cross-validation을 통해 시뮬레이션 해보는 것으로 보완하는 것입니다. 우리가 현실에서 받을 수 있는 데이터는 무한개가 아니라 한 개 이므로 n-fold 크로스 밸리데이션을 사용해서 여러번 샘플링하고 시뮬레이션을 통해 많은 데이터를 트레이닝 해봤다고 가정해서 테스트해 해보는 것이다. 하나 남겨두고 모두를 트레이닝 하고, 남겨둔 하나로 테스트하는 방법을 쓰는 것입니다. 이런 방식을 반복하면 n번만큼 할 수 있습니다. 이것을 하는 이유는 n번을 통해 무한대의 데이터를 다뤄봤고, 그 과정을 통해 average 가설을 구하려고 하는것이다. 에러를 계산하려면 필요한 과정임을 위에 수식에서 설명하고 있습니다.

또 하나 정규화 과정이 필요합니다.

모델에 대한 regularization을 자세히 설명 해보도록 하겠습니다.
variance에 의해 생기는 에러는 무시못할만큼 심각할 수 있습니다.
perfect fit을 포기하고 새로운 데이터가 들어 왔을때 일반적으로 잘 맞출수 있게 평탄하게 모델을 만들어 주는 것 입니다.그래서 정규화 시키는 방법은 복잡한 모델은 쓰되 여기서 생기는 바이어스를 줄이기 위해 정규화 텀을 둬서 좀 둔감하게 만들어 주고 전체적인 트렌드는 잘 따라가자는 의미로 만들어 주는 텀입니다
 둥글해서 유도가 쉽습니다
모델에 맞춰서 선택해서 사용이 가능하고 에러텀에 추가를 해서 optimization을 해야합니다. 
이와 관련된 이론으로 Ocam's razor가 있는데 이 이론은 에러가 같다면 심플한 모델이 더 좋은 모델이라는 이론이고 알아두면 좋을 것 같습니다. ( 오버피팅보단 안정적인 모델을 선호한다)
